# æŠ€è¡“å¯¦ç¾å¯©æŸ¥çµæœ

## TODO: High Priority

[ ] å¯¦ç¾ StreamingChunk schema å’Œ backpressure
    æª”æ¡ˆï¼šsre-assistant/utils/a2a_client.py (Line 45-80)
    æª”æ¡ˆï¼šsre-assistant/__init__.py (Line 35-55)
    æ–°å¢ï¼šsre-assistant/a2a/protocol.py (éœ€å‰µå»º)

[ ] é·ç§»åˆ°å®˜æ–¹ MatchingEngineIndexEndpoint API  
    æª”æ¡ˆï¼šsre-assistant/memory.py (Line 85-120)
    ç‰¹åˆ¥æ˜¯ _create_vector_backend() æ–¹æ³•éœ€è¦é‡å¯«

[ ] æ·»åŠ  50 ä¸¦ç™¼æœƒè©±æ¸¬è©¦
    æª”æ¡ˆï¼štest/test_agent.py (éœ€æ–°å¢æ¸¬è©¦æ–¹æ³•)
    æ–°å¢ï¼štest/test_concurrent_sessions.py (éœ€å‰µå»º)
    æ–°å¢ï¼štest/test_contracts.py (éœ€å‰µå»º)

[ ] å¯¦ç¾å·¥å…·ç‰ˆæœ¬ç›¸å®¹æ€§æª¢æŸ¥
    æª”æ¡ˆï¼šsre-assistant/tools.py (Line 45-75)
    éœ€è¦åœ¨ VersionedToolRegistry é¡åˆ¥ä¸­è£œå…… check_compatibility() æ–¹æ³•

## TODO: Medium Priority  
[ ] åŠ å…¥ 5 Whys postmortem æ¨¡æ¿
    æª”æ¡ˆï¼šsub_agents/postmortem/agent.py (Line 35-60)
    æª”æ¡ˆï¼šsub_agents/postmortem/prompts.py (éœ€è£œå……æ¨¡æ¿)
    æª”æ¡ˆï¼šsub_agents/postmortem/tools.py (ReportGeneratorTool)

[ ] å¯¦ç¾ SLO é•è¦è‡ªå‹•å›æ»¾
    æª”æ¡ˆï¼šsre-assistant/slo_manager.py (Line 180-220)
    æª”æ¡ˆï¼šsub_agents/remediation/tools.py (ConfigRollbackTool)

[ ] å„ªåŒ– ParallelAgent æ¬Šé‡ç®—æ³•
    æª”æ¡ˆï¼šsre-assistant/agent.py (Line 115-125)
    ç‰¹åˆ¥æ˜¯ diagnostic_phase çš„ weights è¨­å®š

## TODO: Low Priority
[ ] æ·»åŠ  Terraform æ¨¡çµ„ç¯„ä¾‹
    æ–°å¢ï¼šdeployment/terraform/main.tf
    æ–°å¢ï¼šdeployment/terraform/variables.tf
    æ–°å¢ï¼šdeployment/terraform/modules/agent_engine/

[ ] å¯¦ç¾ canary éƒ¨ç½²ç­–ç•¥
    æª”æ¡ˆï¼šdeployment/deploy.py (éœ€è£œå…… canary é‚è¼¯)
    æª”æ¡ˆï¼šdeployment/cloudbuild.yaml (éœ€æ–°å¢ canary steps)

[ ] å„ªåŒ– Docker é¡åƒå¤§å°
    æª”æ¡ˆï¼šdeployment/Dockerfile (éœ€å„ªåŒ–)

### âš ï¸ éƒ¨åˆ†æ”¹é€²ä½†ä»éœ€åŠ å¼·çš„é ˜åŸŸ

#### 1. **A2A Streaming å¯¦ç¾ï¼ˆéƒ¨åˆ†æ”¹é€²ï¼‰**
```python
# ç¾æœ‰å¯¦ç¾
async def _execute_with_streaming(self, context, event_queue, query):
    async for chunk in self.agent.execute_streaming(query):
        # åŸºæœ¬ streaming è™•ç†
```

**å•é¡Œ**ï¼š
- ç¼ºå°‘ refactor-2.md å»ºè­°çš„ backpressure handling
- æœªå¯¦ç¾ idempotency token æ©Ÿåˆ¶
- ç¼ºå°‘ chunk schema å®šç¾©

**å»ºè­°æ”¹é€²**ï¼š
```python
# åŠ å…¥å®Œæ•´ streaming å”è­°
@dataclass
class StreamingChunk:
    chunk_id: str
    timestamp: datetime
    type: Literal["progress", "partial_result", "metrics_update"]
    progress: float
    partial_result: Optional[Dict]
    idempotency_token: str
    
class StreamingHandler:
    def __init__(self):
        self.buffer = deque(maxlen=1000)  # Backpressure
        self.seen_tokens = set()  # å†ªç­‰æ€§
        
    async def handle_with_flow_control(self, chunk: StreamingChunk):
        if chunk.idempotency_token in self.seen_tokens:
            return  # é˜²æ­¢é‡è¤‡è™•ç†
        # æµé‡æ§åˆ¶é‚è¼¯
```

#### 2. **è¨˜æ†¶é«”ç®¡ç† API ä½¿ç”¨ï¼ˆéœ€æ›´æ–°ï¼‰**
**å•é¡Œ**ï¼šä»ä½¿ç”¨è‡ªå®šç¾© `generate_embedding` è€Œéå®˜æ–¹ API

**å»ºè­°æ”¹é€²**ï¼š
```python
# ä½¿ç”¨å®˜æ–¹ MatchingEngineIndexEndpoint API
from google.cloud.aiplatform.matching_engine import MatchingEngineIndexEndpoint

class SREMemorySystem:
    def __init__(self):
        self.index_endpoint = MatchingEngineIndexEndpoint(
            index_endpoint_name="projects/.../indexEndpoints/..."
        )
    
    async def upsert_vectors(self, data):
        # ä½¿ç”¨å®˜æ–¹ API
        return await self.index_endpoint.upsert_datapoints(
            datapoints=data,
            update_mask=["restricts", "crowding_tag"]
        )
```


#### 3. **æ¸¬è©¦è¦†è“‹åº¦ï¼ˆrefactor-2.md å¼·èª¿ä½†æœªå¯¦ç¾ï¼‰**
**ç¼ºå¤±**ï¼š
- ç¼ºå°‘ contract tests é©—è­‰å·¥å…·å‘¼å«
- ç„¡ä¸¦ç™¼æ¸¬è©¦ï¼ˆå»ºè­°çš„ 50 concurrent runsï¼‰
- ç¼ºå°‘ hypothesis å±¬æ€§æ¸¬è©¦

**å¿…è¦è£œå……**ï¼š
```python
# test/test_contracts.py
import hypothesis.strategies as st
from hypothesis import given

class TestContracts:
    @given(st.builds(SRERequest))
    def test_request_contract(self, request):
        # å±¬æ€§æ¸¬è©¦ç¢ºä¿å¥‘ç´„å®Œæ•´æ€§
        assert request.incident_id
        
    def test_concurrent_sessions(self):
        # 50 ä¸¦ç™¼æœƒè©±æ¸¬è©¦
        async def run_session(id):
            return await coordinator.execute(...)
        
        results = await asyncio.gather(*[
            run_session(i) for i in range(50)
        ])
```

#### 4. **å·¥å…·ç‰ˆæœ¬ç®¡ç†ï¼ˆrefactor-2.md å»ºè­°æœªå¯¦ç¾ï¼‰**
**ç¼ºå¤±**ï¼šç¼ºå°‘å·¥å…·ç‰ˆæœ¬ç›¸å®¹æ€§çŸ©é™£

**å¿…è¦è£œå……**ï¼š
```python
class VersionedToolRegistry(ToolRegistry):
    def __init__(self):
        self.compatibility_matrix = {
            "PromQLQueryTool": {
                "2.1.0": ["prometheus>=2.40"],
                "2.0.0": ["prometheus>=2.35"]
            }
        }
    
    def check_compatibility(self, tool_name: str, version: str):
        # é©—è­‰å·¥å…·ç‰ˆæœ¬ç›¸å®¹æ€§
        pass
```

## å®Œå–„å»ºè­°å„ªå…ˆç´š

### P0 - ç«‹å³ä¿®å¾©ï¼ˆå½±éŸ¿ç”Ÿç”¢ç©©å®šæ€§ï¼‰
1. **è£œå……ä¸¦ç™¼æ¸¬è©¦**ï¼šæ·»åŠ  50+ ä¸¦ç™¼æœƒè©±æ¸¬è©¦ï¼Œç¢ºä¿ç”Ÿç”¢è² è¼‰ä¸‹ç©©å®šæ€§
2. **å¯¦ç¾å®Œæ•´ streaming å”è­°**ï¼šåŠ å…¥ backpressure å’Œ idempotency æ©Ÿåˆ¶
3. **å¼·åŒ–éŒ¯èª¤æ¢å¾©**ï¼šç‚ºæ‰€æœ‰é•·æ™‚é–“é‹è¡Œæ“ä½œæ·»åŠ  circuit breaker

### P1 - çŸ­æœŸæ”¹é€²ï¼ˆ1-2 é€±ï¼‰
1. **å‡ç´šè¨˜æ†¶é«” API**ï¼šé·ç§»åˆ°å®˜æ–¹ MatchingEngineIndexEndpoint
2. **å®Œå–„å·¥å…·ç‰ˆæœ¬ç®¡ç†**ï¼šå¯¦ç¾ compatibility_matrix å’Œè‡ªå‹•é™ç´š
3. **å¢å¼· A2A èªè­‰**ï¼šå¯¦ç¾å®Œæ•´ token refresh å’Œ mTLS

### P2 - ä¸­æœŸå„ªåŒ–ï¼ˆ1 å€‹æœˆï¼‰
1. **æ“´å±•è©•ä¼°æ¡†æ¶**ï¼šåŠ å…¥ trajectory evaluation å’Œæ¥­å‹™æŒ‡æ¨™
2. **å„ªåŒ–ç·©å­˜ç­–ç•¥**ï¼šå¯¦ç¾åˆ†å±¤ç·©å­˜ï¼ˆL1/L2/L3ï¼‰
3. **åŠ å¼·å¯è§€æ¸¬æ€§**ï¼šæ•´åˆ OpenTelemetry åˆ†æ•£å¼è¿½è¹¤



## 2. éå®˜æ–¹ API å¯¦ç¾è©³ç´°æ¸…å–®

### ğŸ”´ **è¨˜æ†¶é«”ç®¡ç† - æœ€åš´é‡çš„éå®˜æ–¹å¯¦ç¾**


**å®˜æ–¹ Vertex AI å¯¦ç¾**ï¼š
```python
# æ­£ç¢ºçš„å®˜æ–¹å¯¦ç¾
from google.cloud.aiplatform.matching_engine import (
    MatchingEngineIndexEndpoint,
    MatchingEngineIndex
)

class SREMemorySystem:
    def __init__(self):
        # ä½¿ç”¨å®˜æ–¹ API
        self.index_endpoint = MatchingEngineIndexEndpoint(
            index_endpoint_name="projects/{}/locations/{}/indexEndpoints/{}"
        )
        
    async def upsert_vectors(self, embeddings, metadata):
        # å®˜æ–¹ upsert_datapoints æ–¹æ³•
        response = self.index_endpoint.upsert_datapoints(
            datapoints=[
                {
                    "datapoint_id": id,
                    "feature_vector": embedding,
                    "restricts": [{"namespace": "sre_knowledge"}]
                }
            ]
        )
        
    async def search_similar(self, query_embedding):
        # å®˜æ–¹ find_neighbors æ–¹æ³•
        response = self.index_endpoint.find_neighbors(
            deployed_index_id="sre_knowledge",
            queries=[query_embedding],
            num_neighbors=10
        )
```

### ğŸŸ¡ **åµŒå…¥ç”Ÿæˆ - ä½¿ç”¨è‡ªå®šç¾©è€Œéå®˜æ–¹ API**

**ä½ç½®**ï¼š`sre-assistant/memory.py`

**å•é¡Œ**ï¼šæ–‡æª”ä¸­æåˆ°ä½†æœªé¡¯ç¤ºå¯¦éš›ç¨‹å¼ç¢¼çš„ `generate_embedding` æ–¹æ³•

**æ‡‰è©²ä½¿ç”¨çš„å®˜æ–¹ API**ï¼š
```python
from vertexai.language_models import TextEmbeddingModel

class SREMemorySystem:
    def __init__(self):
        # å®˜æ–¹åµŒå…¥æ¨¡å‹
        self.embedding_model = TextEmbeddingModel.from_pretrained(
            "textembedding-gecko@003"
        )
    
    def generate_embeddings(self, texts: List[str]):
        # ä½¿ç”¨å®˜æ–¹ API ç”ŸæˆåµŒå…¥
        embeddings = self.embedding_model.get_embeddings(texts)
        return [emb.values for emb in embeddings]
```

### ğŸŸ¡ **A2A èªè­‰ - ä¸å®Œæ•´çš„å®˜æ–¹å¯¦ç¾**

**ä½ç½®**ï¼š`sre-assistant/utils/a2a_client.py`

**å•é¡Œç¨‹å¼ç¢¼**ï¼ˆLine 25-35ï¼‰ï¼š
```python
# ç°¡åŒ–çš„èªè­‰é…ç½®
auth_config={
    "type": "oauth2",
    "client_id": "sre-assistant-client",
    "client_secret": os.getenv("A2A_CLIENT_SECRET"),
    "auto_refresh": True,  # åªæ˜¯æ¨™è¨˜ï¼Œæœªå¯¦ç¾
}
```

**ç¼ºå°‘çš„å®˜æ–¹å¯¦ç¾**ï¼š
```python
# æ‡‰è©²ä½¿ç”¨å®˜æ–¹ Google Auth åº«
from google.auth import jwt
from google.auth.transport.requests import Request

class A2AAuthManager:
    def __init__(self):
        self.credentials = jwt.Credentials.from_service_account_file(
            "service-account.json",
            scopes=["https://www.googleapis.com/auth/cloud-platform"]
        )
    
    def refresh_token(self):
        # å®˜æ–¹ token åˆ·æ–°æ©Ÿåˆ¶
        if self.credentials.expired:
            self.credentials.refresh(Request())
        return self.credentials.token
```

### ğŸŸ¡ **éƒ¨ç½² API - ç°¡åŒ–ç‰ˆè€Œéå®Œæ•´å®˜æ–¹ API**

**ä½ç½®**ï¼š`deployment/deploy.py` (åƒ…åœ¨æ¶æ§‹ä¸­æåŠ)

**å•é¡Œ**ï¼šä½¿ç”¨ç°¡åŒ–çš„éƒ¨ç½²æ–¹æ³•

**æ‡‰è©²ä½¿ç”¨çš„å®˜æ–¹ API**ï¼š
```python
from google.cloud import aiplatform
from google.cloud.aiplatform.preview import agents

# å®˜æ–¹ Agent Engine éƒ¨ç½² API
def deploy_to_agent_engine():
    aiplatform.init(project="your-project", location="us-central1")
    
    # å®˜æ–¹ Agent éƒ¨ç½²
    agent = agents.Agent.create(
        display_name="sre-assistant",
        model="gemini-2.0-flash",
        tools=[...],
        system_instruction=GLOBAL_SRE_PROMPT
    )
    
    # å®˜æ–¹ç«¯é»å‰µå»º
    endpoint = agent.deploy(
        machine_type="n1-standard-4",
        min_replica_count=2,
        max_replica_count=10,
        accelerator_type=None,
        service_account="sre-assistant@project.iam.gserviceaccount.com"
    )
```

### ğŸŸ¢ **Callbacks - æ­£ç¢ºä½†å¯å„ªåŒ–**

**ä½ç½®**ï¼š`sre-assistant/agent.py` (Line 75-95)

é›–ç„¶ä½¿ç”¨äº† `SafetyCallback` å’Œ `AuditCallback`ï¼Œä½†æŸäº›æ–¹æ³•æ˜¯è‡ªå®šç¾©çš„ï¼š
```python
# è‡ªå®šç¾©æ–¹æ³•ï¼ˆéæ¨™æº–ï¼‰
SafetyCallback(
    risk_assessor=self._assess_risk,  # è‡ªå®šç¾©
    pii_scrubber=self._scrub_pii,     # è‡ªå®šç¾©
)
```

é€™äº›è‡ªå®šç¾©æ˜¯å¯æ¥å—çš„æ“´å±•ï¼Œä½†æ‡‰ç¢ºä¿ç¹¼æ‰¿å®˜æ–¹åŸºé¡ã€‚

## ç¸½çµ

æœ€åš´é‡çš„éå®˜æ–¹ API ä½¿ç”¨æ˜¯ï¼š
1. **Vertex AI Vector Search (MatchingEngineIndexEndpoint)** - è¨˜æ†¶é«”ç®¡ç†å®Œå…¨ä½¿ç”¨è‡ªå®šç¾©å¯¦ç¾
2. **TextEmbeddingModel** - åµŒå…¥ç”Ÿæˆæœªä½¿ç”¨å®˜æ–¹ API
3. **A2A èªè­‰** - Token åˆ·æ–°æ©Ÿåˆ¶ä¸å®Œæ•´
4. **Agent Engine éƒ¨ç½²** - ä½¿ç”¨ç°¡åŒ–ç‰ˆè€Œéå®Œæ•´å®˜æ–¹ API

å»ºè­°å„ªå…ˆä¿®å¾©è¨˜æ†¶é«”ç®¡ç†å’ŒåµŒå…¥ç”Ÿæˆçš„ API ä½¿ç”¨ï¼Œå› ç‚ºé€™äº›æ˜¯æ ¸å¿ƒåŠŸèƒ½ä¸”å½±éŸ¿ç³»çµ±æ€§èƒ½å’Œç›¸å®¹æ€§ã€‚


